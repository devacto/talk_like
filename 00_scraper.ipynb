{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper\n",
    "\n",
    "> Functions to scrape things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facebook-scraper\n",
      "  Using cached facebook_scraper-0.2.17-py3-none-any.whl (16 kB)\n",
      "Collecting dateparser<2.0.0,>=1.0.0\n",
      "  Using cached dateparser-1.0.0-py2.py3-none-any.whl (279 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/miniconda3/envs/talk_like/lib/python3.8/site-packages (from dateparser<2.0.0,>=1.0.0->facebook-scraper) (2.8.1)\n",
      "Collecting regex!=2019.02.19\n",
      "  Downloading regex-2020.11.13-cp38-cp38-macosx_10_9_x86_64.whl (284 kB)\n",
      "\u001b[K     |████████████████████████████████| 284 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-html<0.11.0,>=0.10.0\n",
      "  Using cached requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Collecting pyppeteer>=0.0.14\n",
      "  Using cached pyppeteer-0.2.5-py3-none-any.whl (87 kB)\n",
      "Collecting appdirs<2.0.0,>=1.4.3\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pyee<9.0.0,>=8.1.0\n",
      "  Using cached pyee-8.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tqdm<5.0.0,>=4.42.1\n",
      "  Using cached tqdm-4.55.1-py2.py3-none-any.whl (68 kB)\n",
      "Collecting urllib3<2.0.0,>=1.25.8\n",
      "  Using cached urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting websockets<9.0,>=8.1\n",
      "  Downloading websockets-8.1-cp38-cp38-macosx_10_9_x86_64.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 2.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting bs4\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.1-py3-none-any.whl (32 kB)\n",
      "Collecting fake-useragent\n",
      "  Using cached fake-useragent-0.1.11.tar.gz (13 kB)\n",
      "Collecting parse\n",
      "  Using cached parse-1.18.0.tar.gz (30 kB)\n",
      "Collecting pyquery\n",
      "  Using cached pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting cssselect>0.7.9\n",
      "  Using cached cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting lxml>=2.1\n",
      "  Downloading lxml-4.6.2-cp38-cp38-macosx_10_9_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/miniconda3/envs/talk_like/lib/python3.8/site-packages (from python-dateutil->dateparser<2.0.0,>=1.0.0->facebook-scraper) (1.15.0)\n",
      "Collecting pytz\n",
      "  Using cached pytz-2020.5-py2.py3-none-any.whl (510 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/talk_like/lib/python3.8/site-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook-scraper) (2020.12.5)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting tzlocal\n",
      "  Using cached tzlocal-2.1-py2.py3-none-any.whl (16 kB)\n",
      "Collecting w3lib\n",
      "  Using cached w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: bs4, fake-useragent, parse\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=f6fdc1901e8c1ad54455b195b86be556b2223954aff38088719a66e2090f53d7\n",
      "  Stored in directory: /Users/vwibisono/Library/Caches/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "  Building wheel for fake-useragent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13486 sha256=9e224295aabc0415c0f42b8d4eb30920bfcabf12968f87876d565b5af6441dfa\n",
      "  Stored in directory: /Users/vwibisono/Library/Caches/pip/wheels/a0/b8/b7/8c942b2c5be5158b874a88195116b05ad124bac795f6665e65\n",
      "  Building wheel for parse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for parse: filename=parse-1.18.0-py3-none-any.whl size=24133 sha256=9e8ed2488e0bd3f48e52b6e86ab05b36e75fbedd3677af1894546a5b46edd771\n",
      "  Stored in directory: /Users/vwibisono/Library/Caches/pip/wheels/5c/94/79/32557465cdb2d7d6d72ba2499632d89ba84fce50a91ae98f14\n",
      "Successfully built bs4 fake-useragent parse\n",
      "Installing collected packages: soupsieve, websockets, urllib3, tqdm, pytz, pyee, lxml, idna, cssselect, chardet, beautifulsoup4, appdirs, w3lib, tzlocal, requests, regex, pyquery, pyppeteer, parse, fake-useragent, bs4, requests-html, dateparser, facebook-scraper\n",
      "Successfully installed appdirs-1.4.4 beautifulsoup4-4.9.3 bs4-0.0.1 chardet-4.0.0 cssselect-1.1.0 dateparser-1.0.0 facebook-scraper-0.2.17 fake-useragent-0.1.11 idna-2.10 lxml-4.6.2 parse-1.18.0 pyee-8.1.0 pyppeteer-0.2.5 pyquery-1.4.3 pytz-2020.5 regex-2020.11.13 requests-2.25.1 requests-html-0.10.0 soupsieve-2.1 tqdm-4.55.1 tzlocal-2.1 urllib3-1.26.2 w3lib-1.22.0 websockets-8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install facebook-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, username=''):\n",
    "        self.username = username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastcore in /opt/miniconda3/envs/talk_like/lib/python3.8/site-packages (1.3.18)\r\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/talk_like/lib/python3.8/site-packages (from fastcore) (20.8)\r\n",
      "Requirement already satisfied: pip in /opt/miniconda3/envs/talk_like/lib/python3.8/site-packages (from fastcore) (20.3.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/miniconda3/envs/talk_like/lib/python3.8/site-packages (from packaging->fastcore) (2.4.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.foundation import patch\n",
    "from facebook_scraper import get_posts\n",
    "\n",
    "@patch\n",
    "def get_facebook_posts(self:Scraper):\n",
    "    return get_posts(self.username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object FacebookScraper._generic_get_posts at 0x7fe5108b9040>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyScraper = Scraper(username='leehsienloong')\n",
    "MyScraper.get_facebook_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def print_something():\n",
    "    print('something')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_scraper.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
